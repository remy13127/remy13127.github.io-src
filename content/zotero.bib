
@article{butscher_radical-assisted_2019,
	title = {Radical-assisted polymerization in interstellar ice analogues: formyl radical and polyoxymethylene},
	volume = {486},
	issn = {0035-8711},
	shorttitle = {Radical-assisted polymerization in interstellar ice analogues},
	url = {https://academic.oup.com/mnras/article/486/2/1953/5423328},
	doi = {10.1093/mnras/stz879},
	abstract = {ABSTRACT.  We present new laboratory experiments on the low-temperature formation of complex organic molecules (COMs) such as polyoxymethylene (POM), glycolalde},
	language = {en},
	number = {2},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Butscher, T. and Duvernay, F. and Danger, G. and Torro, R. and Lucas, G. and Carissan, Y. and Hagebaum-Reignier, D. and Chiavassa, T.},
	month = jun,
	year = {2019},
	pages = {1953--1963}
}

@article{rueda-orozco_striatum_2015,
	title = {The striatum multiplexes contextual and kinematic information to constrain motor habits execution},
	volume = {18},
	copyright = {2015 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3924},
	doi = {10.1038/nn.3924},
	abstract = {The striatum is required for the acquisition of procedural memories, but its contribution to motor control once learning has occurred is unclear. We created a task in which rats learned a difficult motor sequence characterized by fine-tuned changes in running speed adjusted to spatial and temporal constraints. After training and extensive practice, we found that the behavior was habitual, yet tetrode recordings in the dorsolateral striatum (DLS) revealed continuous integrative representations of running speed, position and time. These representations were weak in naive rats that were hand-guided to perform the same sequence and developed slowly after learning. Finally, DLS inactivation in well-trained animals preserved the structure of the sequence while increasing its trial-by-trial variability. We conclude that, after learning, the DLS continuously integrates task-relevant information to constrain the execution of motor habits. Our results provide a straightforward mechanism by which the basal ganglia may contribute to habit formation and motor control.},
	language = {en},
	number = {3},
	journal = {Nature Neuroscience},
	author = {Rueda-Orozco, Pavel E. and Robbe, David},
	month = mar,
	year = {2015},
	pages = {453--460}
}

@article{sales-carbonell_no_2018,
	title = {No {Discrete} {Start}/{Stop} {Signals} in the {Dorsal} {Striatum} of {Mice} {Performing} a {Learned} {Action}},
	volume = {28},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982218309370},
	doi = {10.1016/j.cub.2018.07.038},
	abstract = {Summary
A popular hypothesis is that the dorsal striatum generates discrete “traffic light” signals that initiate, maintain, and terminate the execution of learned actions. Alternatively, the striatum may continuously monitor the dynamics of movements associated with action execution by processing inputs from somatosensory and motor cortices. Here, we recorded the activity of striatal neurons in mice performing a run-and-stop task and characterized the diversity of firing rate modulations relative to run performance (tuning curves) across neurons. We found that the tuning curves could not be statistically clustered in discrete functional groups (start or stop neurons). Rather, their shape varied continuously according to the movement dynamics of the task. Moreover, striatal spiking activity correlated with running speed on a run-by-run basis and was modulated by task-related non-locomotor movements, such as licking. We hypothesize that such moment-to-moment movement monitoring by the dorsal striatum contributes to the learning of adaptive actions and/or updating their kinematics.},
	number = {19},
	journal = {Current Biology},
	author = {Sales-Carbonell, Carola and Taouali, Wahiba and Khalki, Loubna and Pasquet, Matthieu O. and Petit, Ludovic F. and Moreau, Typhaine and Rueda-Orozco, Pavel E. and Robbe, David},
	month = oct,
	year = {2018},
	keywords = {Bayesian decoding, action, basal ganglia, behavior, caudate, locomotion, movement, neuronal sequence, population activity, putamen},
	pages = {3044--3055.e5}
}

@article{mureika_simple_1997,
	title = {A {Simple} {Model} for {Predicting} {Sprint} {Race} {Times} {Accounting} for {Energy} {Loss} on the {Curve}},
	volume = {75},
	issn = {0008-4204, 1208-6045},
	url = {http://arxiv.org/abs/physics/9704022},
	doi = {10.1139/cjp-75-11-837},
	abstract = {The mathematical model of J. Keller for predicting World Record race times, based on a simple differential equation of motion, predicted quite well the records of the day. One of its shortcoming is that it neglects to account for a sprinter's energy loss around a curve, a most important consideration particularly in the 200m--400m. An extension to Keller's work is considered, modeling the aforementioned energy loss as a simple function of the centrifugal force acting on the runner around the curve. Theoretical World Record performances for indoor and outdoor 200m are discussed, and the use of the model at 300m is investigated. Some predictions are made for possible 200m outdoor and indoor times as run by Canadian 100m WR holder Donovan Bailey, based on his 100m final performance at the 1996 Olympic Games in Atlanta.},
	number = {11},
	journal = {Canadian Journal of Physics},
	author = {Mureika, J. R.},
	month = nov,
	year = {1997},
	note = {arXiv: physics/9704022},
	keywords = {Physics - Popular Physics},
	pages = {837--851}
}

@article{aftalion_how_2016,
	title = {How to identify the physiological parameters and run the optimal race},
	volume = {7},
	issn = {2102-5754},
	url = {http://msia.cedram.org/item?id=MSIA_2016__7_1_1_0},
	doi = {10.5802/msia.9},
	abstract = {This paper shows how a system of ordinary diﬀerential equations describing the evolution of the anaerobic energy, the oxygen uptake, the propulsive force and the velocity of a runner accurately describes pacing strategy. We ﬁnd a protocol to identify the physiological parameters needed in the model using numerical simulations and time splits measurements for an 80 m and a 1600 m race. The velocity curve of the simulations is very close to the experimental one. This model could allow to study the inﬂuence of training and improving some speciﬁc parameters for the pacing strategy.},
	language = {en},
	number = {1},
	journal = {MathematicS In Action},
	author = {Aftalion, Amandine and Despaigne, Louis-Henri and Frentz, Alexis and Gabet, Pierre and Lajouanie, Antoine and Lorthiois, Marc-Antoine and Roquette, Lucien and Vernet, Camille},
	year = {2016},
	pages = {1--10}
}

@article{andersson_casadi:_2019,
	title = {{CasADi}: a software framework for nonlinear optimization and optimal control},
	volume = {11},
	issn = {1867-2957},
	shorttitle = {{CasADi}},
	url = {https://doi.org/10.1007/s12532-018-0139-4},
	doi = {10.1007/s12532-018-0139-4},
	abstract = {We present CasADi, an open-source software framework for numerical optimization. CasADi is a general-purpose tool that can be used to model and solve optimization problems with a large degree of flexibility, larger than what is associated with popular algebraic modeling languages such as AMPL, GAMS, JuMP or Pyomo. Of special interest are problems constrained by differential equations, i.e. optimal control problems. CasADi is written in self-contained C++, but is most conveniently used via full-featured interfaces to Python, MATLAB or Octave. Since its inception in late 2009, it has been used successfully for academic teaching as well as in applications from multiple fields, including process control, robotics and aerospace. This article gives an up-to-date and accessible introduction to the CasADi framework, which has undergone numerous design improvements over the last 7 years.},
	language = {en},
	number = {1},
	journal = {Mathematical Programming Computation},
	author = {Andersson, Joel A. E. and Gillis, Joris and Horn, Greg and Rawlings, James B. and Diehl, Moritz},
	month = mar,
	year = {2019},
	keywords = {90C99, 93A30, 97A01, Open source optimization software, Optimal control, Optimization},
	pages = {1--36}
}

@inproceedings{andersson_dynamic_2012,
	title = {Dynamic optimization with {CasADi}},
	doi = {10.1109/CDC.2012.6426534},
	abstract = {We demonstrate how CasADi, a recently developed, free, open-source, general purpose software tool for nonlinear optimization, can be used for dynamic optimization in a flexible, interactive and numerically efficient way. CasADi is best described as a minimalistic computer algebra system (CAS) implementing automatic differentiation (AD) in eight different flavors. Similar to algebraic modeling languages like AMPL or GAMS, it includes high-level interfaces to state-of-the-art numerical codes for nonlinear programming, quadratic programming and integration of differentialalgebraic equations. CasADi is implemented in self-contained C++ code and contains full-featured front-ends to Python and Octave for rapid prototyping. In this paper, we discuss CasADi from the perspective of the developer or advanced user of algorithms for dynamic optimization for the first time, leaving out details on the implementation of the tool. We demonstrate how the tool can be used to model highly complex dynamical systems directly or import existing models formulated in the algebraic modeling language AMPL or the physical modeling language Modelica. Given this symbolic representation of the process models, the resulting optimal control problem can be solved using a variety of methods, including transcription methods (collocation), methods with embedded integrators (multiple shooting) as well as indirect methods.},
	booktitle = {2012 {IEEE} 51st {IEEE} {Conference} on {Decision} and {Control} ({CDC})},
	author = {Andersson, J. and Åkesson, J. and Diehl, M.},
	month = dec,
	year = {2012},
	keywords = {AD, AMPL algebraic modeling language, C++ code, C++ language, CAS, CasADi*, Computers, Equations, GAMS algebraic modeling language, Jacobian matrices, Mathematical model, Modelica physical modeling language, Numerical models, Octave, Optimal control, Optimization, Python, automatic differentiation, collocation transcription methods, complex dynamical system model, computer algebra system, differential-algebraic equation integration, differentiation, dynamic optimization, dynamic programming, free open-source general purpose software tool, high-level interfaces, indirect methods, integration, interactive systems, multiple shooting embedded integrators, nonlinear programming, numerical codes, optimal control problem, process models, public domain software, quadratic programming, rapid prototyping, symbol manipulation, symbolic representation},
	pages = {681--686}
}

@inproceedings{press_0521806151-collocation_1_nodate,
	title = {1 {The} collocation method for {ODEs} : an introduction},
	shorttitle = {1 {The} collocation method for {ODEs}},
	abstract = {A collocation solution u h to a functional equation (for example an ordinary differential equation or a Volterra integral equation) on an interval I is an element from some finite-dimensional function space (the collocation space) which satisfies the equation on an appropriate finite subset of points in I (the set of collocation points) whose cardinality essentially matches the dimension of the collocation space. If initial (or boundary) conditions are present then u h will usually be required to fulfil these conditions, too. The use of polynomial or piecewise polynomial collocation spaces for the approximate solution of boundary-value problems has its origin in the 1930s. For initial-value problems in ordinary differential equations such collocation methods were first studied systematically in the late 1960s: it was then shown that collocation in continuous piecewise polynomial spaces leads to an important class of implicit (high-order) Runge–Kutta methods. Consider the initial-value problem y (t) = f (t, y(t)), t ∈ I := [0, T ], y(0) = y 0 , (1.1.1) and assume that the (Lipschitz-) continuous function f : I × ⊂ IR → IR is such that (1.1.1) possesses a unique solution y ∈ C 1 (I) for all y 0 ∈. Let I h := \{t n : 0 = t 0 {\textless} t 1 {\textless}. .. {\textless} t N = T \} be a given (not necessarily uniform) mesh on I , and set σ n := (t n , t n+1 ], ¯},
	author = {Press 0521806151-Collocation},
	keywords = {Approximation algorithm, Collocation method, Lotka–Volterra equations, Polynomial, Runge–Kutta methods, Subgroup}
}

@article{weir_new_1949,
	title = {New methods for calculating metabolic rate with special reference to protein metabolism},
	volume = {109},
	issn = {0022-3751},
	doi = {10.1113/jphysiol.1949.sp004363},
	language = {eng},
	number = {1-2},
	journal = {The Journal of Physiology},
	author = {Weir, J. B. De B.},
	month = aug,
	year = {1949},
	pmid = {15394301},
	pmcid = {PMC1392602},
	keywords = {Humans, METABOLISM, Metabolism, PROTEINS, Proteins},
	pages = {1--9}
}

@article{khalil_optimality_2017,
	title = {Optimality conditions for optimal control problems and applications},
	url = {https://tel.archives-ouvertes.fr/tel-01740334},
	abstract = {The project of this thesis is twofold. The first concerns the extension of previous results on necessary optimality conditions for state constrained problems in optimal control and in calculus of variations. The second aim consists in working along two new research lines: derive viability results for a class of control systems with state constraints in which ‘standard inward pointing conditions’ are violated; and establish necessary optimality conditions for average cost minimization problems possibly perturbed by unknown parameters.In the first part, we examine necessary optimality conditions which play an important role in finding candidates to be optimal solutions among all admissible solutions. However, in dynamic optimization problems with state constraints, some pathological situations might arise. For instance, it might occur that the multiplier associated with the objective function (to minimize) vanishes. In this case, the objective function to minimize does not intervene in first order necessary conditions: this is referred to as the abnormal case. A worse phenomenon, called the degenerate case shows that in some circumstances the set of admissible trajectories coincides with the set of candidates to be minimizers. Therefore the necessary conditions give no information on the possible minimizers.To overcome these difficulties, new additional hypotheses have to be imposed, known as constraint qualifications. We investigate these two issues (normality and non-degeneracy) for optimal control problems involving state constraints and dynamics expressed as a differential inclusion, when the minimizer has its left end-point in a region where the state constraint set in nonsmooth. We prove that under an additional information involving mainly the Clarke tangent cone, necessary conditions in the form of the Extended Euler-Lagrange condition are derived in the normal and non-degenerate form for two different classes of state constrained optimal control problems. Application of the normality result is shown also for the calculus of variations problem subject to a state constraint.In the second part of the thesis, we consider first a class of state constrained control systems for which standard ‘first order’ constraint qualifications are not satisfied, but a higher (second) order constraint qualification is satisfied. We propose a new construction for feasible trajectories (a viability result) and we investigate examples (such as the Brockett nonholonomic integrator) providing in addition a non-linear stimate result. The other topic of the second part of the thesis concerns the study of a class of optimal control problems in which uncertainties appear in the data in terms of unknown parameters. Taking into consideration an average cost criterion, a crucial issue is clearly to be able to characterize optimal controls independently of the unknown parameter action: this allows to find a sort of ‘best compromise’ among all the possible realizations of the control system as the parameter varies. For this type of problems, we derive necessary optimality conditions in the form of Maximum Principle (possibly nonsmooth).},
	language = {en},
	author = {Khalil, Nathalie},
	month = nov,
	year = {2017}
}

@article{khalil_optimality_nodate,
	title = {Optimality conditions for optimal control problems and applications},
	abstract = {The project of this thesis is twofold. The ﬁrst concerns the extension of previous results on necessary optimality conditions for state constrained problems in optimal control and in calculus of variations. The second aim consists in working along two new research lines: derive viability results for a class of control systems with state constraints in which ‘standard inward pointing conditions’ are violated; and establish necessary optimality conditions for average cost minimization problems possibly perturbed by unknown parameters.},
	language = {en},
	author = {Khalil, Nathalie},
	pages = {192}
}

@article{becerra_optimal_2008,
	title = {Optimal control},
	volume = {3},
	issn = {1941-6016},
	url = {http://www.scholarpedia.org/article/Optimal_control},
	doi = {10.4249/scholarpedia.5354},
	language = {en},
	number = {1},
	journal = {Scholarpedia},
	author = {Becerra, Victor M.},
	month = jan,
	year = {2008},
	pages = {5354}
}

@article{heerey_delay_2007,
	title = {Delay discounting in schizophrenia},
	volume = {12},
	issn = {1354-6805},
	doi = {10.1080/13546800601005900},
	abstract = {BACKGROUND: It is well known that individuals with schizophrenia have dopaminergic abnormalities as well as memory-related difficulties, both of which are associated with impulsive decision making. We used a delay discounting measure to test the degree to which patients make future-oriented decisions.
METHODS: 42 patients with schizophrenia and 29 healthy participants completed a delay discounting measure along with tests of cognitive function and, in patients, symptom ratings.
RESULTS: Patients discounted more steeply than did comparison participants. Discounting among patients related to memory capacity and tended to relate inversely to negative symptoms.
CONCLUSIONS: The impulsive decision making evidenced by patients suggests that they may be prone to choosing immediate over long-term rewards, even when their interests are better served by choosing the latter. Improving cognitive function may enhance their ability to make future-oriented decisions.},
	language = {eng},
	number = {3},
	journal = {Cognitive Neuropsychiatry},
	author = {Heerey, Erin A. and Robinson, Benjamin M. and McMahon, Robert P. and Gold, James M.},
	month = may,
	year = {2007},
	pmid = {17453902},
	pmcid = {PMC3746343},
	keywords = {Adult, Cognition Disorders, Decision Making, Diagnostic and Statistical Manual of Mental Disorders, Disruptive, Impulse Control, and Conduct Disorders, Dopamine, Female, Humans, Male, Neuropsychological Tests, Reward, Schizophrenia, Severity of Illness Index, Surveys and Questionnaires, Time Factors, Time Perception},
	pages = {213--221}
}

@article{osullivan_dissociating_2009,
	title = {Dissociating {Variability} and {Effort} as {Determinants} of {Coordination}},
	volume = {5},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000345},
	doi = {10.1371/journal.pcbi.1000345},
	abstract = {When coordinating movements, the nervous system often has to decide how to distribute work across a number of redundant effectors. Here, we show that humans solve this problem by trying to minimize both the variability of motor output and the effort involved. In previous studies that investigated the temporal shape of movements, these two selective pressures, despite having very different theoretical implications, could not be distinguished; because noise in the motor system increases with the motor commands, minimization of effort or variability leads to very similar predictions. When multiple effectors with different noise and effort characteristics have to be combined, however, these two cost terms can be dissociated. Here, we measure the importance of variability and effort in coordination by studying how humans share force production between two fingers. To capture variability, we identified the coefficient of variation of the index and little fingers. For effort, we used the sum of squared forces and the sum of squared forces normalized by the maximum strength of each effector. These terms were then used to predict the optimal force distribution for a task in which participants had to produce a target total force of 4–16 N, by pressing onto two isometric transducers using different combinations of fingers. By comparing the predicted distribution across fingers to the actual distribution chosen by participants, we were able to estimate the relative importance of variability and effort of 1∶7, with the unnormalized effort being most important. Our results indicate that the nervous system uses multi-effector redundancy to minimize both the variability of the produced output and effort, although effort costs clearly outweighed variability costs.},
	language = {en},
	number = {4},
	journal = {PLOS Computational Biology},
	author = {O'Sullivan, Ian and Burdet, Etienne and Diedrichsen, Jörn},
	month = apr,
	year = {2009},
	keywords = {Fingers, Forearms, Hands, Motor system, Musculoskeletal system, Nervous system, Noise reduction, Wrist},
	pages = {e1000345}
}

@article{fagg_computational_2002,
	title = {A computational model of muscle recruitment for wrist movements},
	volume = {88},
	issn = {0022-3077},
	doi = {10.1152/jn.00621.2002},
	abstract = {To execute a movement, the CNS must appropriately select and activate the set of muscles that will produce the desired movement. This problem is particularly difficult because a variety of muscle subsets can usually be used to produce the same joint motion. The motor system is therefore faced with a motor redundancy problem that must be resolved to produce the movement. In this paper, we present a model of muscle recruitment in the wrist step-tracking task. Muscle activation levels for five muscles are selected so as to satisfy task constraints (moving to the designated target) while also minimizing a measure of the total effort in producing the movement. Imposing these constraints yields muscle activation patterns qualitatively similar to those observed experimentally. In particular, the model reproduces the observed cosine-like recruitment of muscles as a function of movement direction and also appropriately predicts that certain muscles will be recruited most strongly in movement directions that differ significantly from their direction of action. These results suggest that the observed recruitment behavior may not be an explicit strategy employed by the nervous system, but instead may result from a process of movement optimization.},
	language = {eng},
	number = {6},
	journal = {Journal of Neurophysiology},
	author = {Fagg, Andrew H. and Shah, Ashvin and Barto, Andrew G.},
	month = dec,
	year = {2002},
	pmid = {12466451},
	keywords = {Humans, Models, Biological, Movement, Muscle, Skeletal, Posture, Sensitivity and Specificity, Wrist},
	pages = {3348--3358}
}

@article{shadmehr_biological_2012,
	title = {Biological {Learning} and {Control}. {How} the {Brain} {Builds} {Representations}, {Predicts} {Events} and {Makes} {Decisions}.},
	url = {https://www.scholars.northwestern.edu/en/publications/biological-learning-and-control-how-the-brain-builds-representati-2},
	language = {English (US)},
	author = {Shadmehr, R. and Mussa-Ivaldi, F. A.},
	year = {2012}
}

@misc{press_biological_nodate,
	title = {Biological {Learning} and {Control}},
	url = {https://mitpress.mit.edu/books/biological-learning-and-control},
	abstract = {A novel theoretical framework that describes a possible rationale for the regularity in how we move, how we learn, and how our brain predicts events.
                In Biological Learning and Control, Reza Shadmehr and Sandro Mussa-Ivaldi present a theoretical framework for understanding the regularity of the brain's perceptions, its reactions to sensory stimuli, and its control of movements. They offer an account of perception as the combination of prediction and observation: the brain builds internal models that describe what should happen and then combines this prediction with reports from the sensory system to form a belief.Considering the brain's control of movements, and variations despite biomechanical similarities among old and young, healthy and unhealthy, and humans and other animals, Shadmehr and Mussa-Ivaldi review evidence suggesting that motor commands reflect an economic decision made by our brain weighing reward and effort. This evidence also suggests that the brain prefers to receive a reward sooner than later, devaluing or discounting reward with the passage of time; then as the value of the expected reward changes in the brain with the passing of time (because of development, disease, or evolution), the shape of our movements will also change.The internal models formed by the brain provide the brain with an essential survival skill: the ability to predict based on past observations. The formal concepts presented by Shadmehr and Mussa-Ivaldi offer a way to describe how representations are formed, what structure they have, and how the theoretical concepts can be tested.},
	language = {en},
	journal = {The MIT Press},
	author = {Press, The MIT}
}

@article{berret_vigour_2018,
	title = {Vigour of self-paced reaching movement: cost of time and individual traits},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	shorttitle = {Vigour of self-paced reaching movement},
	url = {https://www.nature.com/articles/s41598-018-28979-6},
	doi = {10.1038/s41598-018-28979-6},
	abstract = {People usually move at a self-selected pace in everyday life. Yet, the principles underlying the formation of human movement vigour remain unclear, particularly in view of intriguing inter-individual variability. It has been hypothesized that how the brain values time may be the cornerstone of such differences, beyond biomechanics. Here, we focused on the vigour of self-paced reaching movement and assessed the stability of vigour via repeated measurements within participants. We used an optimal control methodology to identify a cost of time (CoT) function underlying each participant’s vigour, considering a model of the biomechanical cost of movement. We then tested the extent to which anthropometric or psychological traits, namely boredom proneness and impulsivity, could account for a significant part of inter-individual variance in vigour and CoT parameters. Our findings show that the vigour of reaching is largely idiosyncratic and tend to corroborate a relation between the relative steepness of the identified CoT and boredom proneness, a psychological trait relevant to one’s relationship with time in decision-making.},
	language = {En},
	number = {1},
	journal = {Scientific Reports},
	author = {Berret, Bastien and Castanier, Carole and Bastide, Simon and Deroche, Thomas},
	month = jul,
	year = {2018},
	pages = {10655}
}

@article{keller_optimal_1974,
	title = {Optimal {Velocity} in a {Race}},
	volume = {81},
	issn = {0002-9890},
	url = {https://doi.org/10.1080/00029890.1974.11993589},
	doi = {10.1080/00029890.1974.11993589},
	number = {5},
	journal = {The American Mathematical Monthly},
	author = {Keller, Joseph B.},
	month = may,
	year = {1974},
	pages = {474--480}
}

@article{shepherd_oxygen_1976,
	title = {Oxygen uptake of rats at different work intensities},
	volume = {362},
	issn = {1432-2013},
	url = {https://doi.org/10.1007/BF00581173},
	doi = {10.1007/BF00581173},
	abstract = {SummaryAn adaptation of a standard activity wheel has been used to determine oxygen uptake of rats prior to and during exercise at 7 different speeds (16–67 m/min). Pre-exercise oxygen uptake was 2.42±0.10 (S.E.) ml (100 g×min)−1 Oxygen uptake increased linearly with work intensity (running speed). At 16 m/min oxygen uptake was 6.44±0.16 ml (100 g×min)−1 and it increased to a maximal value of 9.51±0.14 ml (100 g×min)−1 at a running speed of 53.6 m/min. Increasing running speed to 67 m/min did not produce any further increas in oxygen uptake. Some comparisons of exercise intensity between rats of various studies and rats and man can be made from these data.},
	language = {en},
	number = {3},
	journal = {Pflügers Archiv},
	author = {Shepherd, R. E. and Gollnick, P. D.},
	month = jan,
	year = {1976},
	keywords = {Aerobic power of rats, Oxygen uptake, Work intensity},
	pages = {219--222}
}

@article{woodside_optimal_1991,
	title = {The optimal strategy for running a race ({A} mathematical model for world records from 50 m to 275 km)},
	volume = {15},
	issn = {08957177},
	url = {https://linkinghub.elsevier.com/retrieve/pii/089571779190086M},
	doi = {10.1016/0895-7177(91)90086-M},
	language = {en},
	number = {10},
	journal = {Mathematical and Computer Modelling},
	author = {Woodside, William},
	year = {1991},
	pages = {1--12}
}

@article{aftalion_how_2016-1,
	title = {How to identify the physiological parameters and run the optimal race},
	volume = {7},
	issn = {2102-5754},
	url = {http://msia.cedram.org/item?id=MSIA_2016__7_1_1_0},
	doi = {10.5802/msia.9},
	abstract = {This paper shows how a system of ordinary diﬀerential equations describing the evolution of the anaerobic energy, the oxygen uptake, the propulsive force and the velocity of a runner accurately describes pacing strategy. We ﬁnd a protocol to identify the physiological parameters needed in the model using numerical simulations and time splits measurements for an 80 m and a 1600 m race. The velocity curve of the simulations is very close to the experimental one. This model could allow to study the inﬂuence of training and improving some speciﬁc parameters for the pacing strategy.},
	language = {en},
	number = {1},
	journal = {MathematicS In Action},
	author = {Aftalion, Amandine and Despaigne, Louis-Henri and Frentz, Alexis and Gabet, Pierre and Lajouanie, Antoine and Lorthiois, Marc-Antoine and Roquette, Lucien and Vernet, Camille},
	year = {2016},
	pages = {1--10}
}

@article{leek_optimal_nodate,
	title = {An {Optimal} {Control} {Toolbox} for {MATLAB}® {Based} on {CasADi}},
	language = {en},
	author = {Leek, Viktor},
	pages = {68}
}

@article{halsey_terrestrial_2016,
	title = {Terrestrial movement energetics: current knowledge and its application to the optimising animal},
	volume = {219},
	issn = {0022-0949, 1477-9145},
	shorttitle = {Terrestrial movement energetics},
	url = {http://jeb.biologists.org/lookup/doi/10.1242/jeb.133256},
	doi = {10.1242/jeb.133256},
	abstract = {The energetic cost of locomotion can be a substantial proportion of an animal’s daily energy budget and thus key to its ecology. Studies on myriad species have added to our knowledge about the general cost of animal movement, including the effects of variations in the environment such as terrain angle. However, further such studies might provide diminishing returns on the development of a deeper understanding of how animals trade-off the cost of movement with other energy costs, and other ecological currencies such as time. Here, I propose the ‘individual energy landscape’ as an approach to conceptualising the choices facing the optimising animal. In this Commentary, first I outline previous broad findings about animal walking and running locomotion, focusing in particular on the use of net cost of transport as a metric of comparison between species, and then considering the effects of environmental perturbations and other extrinsic factors on movement costs. I then introduce and explore the idea that these factors combine with the behaviour of the animal in seeking short-term optimality to create that animal’s individual energy landscape – the result of the geographical landscape and environmental factors combined with the animal’s selected tradeoffs. Considering an animal’s locomotion energy expenditure within this context enables hard-won empirical data on transport costs to be applied to questions about how an animal can and does move through its environment to maximise its fitness, and the relative importance, or otherwise, of locomotion energy economy.},
	language = {en},
	number = {10},
	journal = {The Journal of Experimental Biology},
	author = {Halsey, Lewis G.},
	month = may,
	year = {2016},
	pages = {1424--1431}
}